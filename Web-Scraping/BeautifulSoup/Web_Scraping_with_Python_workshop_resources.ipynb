{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Web Scraping with Python Workshop Resources </h1>"
      ],
      "metadata": {
        "id": "1PQu0RyLcitR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web scraping is an automatic method to obtain large amounts of data from websites.\n",
        "Web scraping is used for:\n",
        "- Price monitoring\n",
        "- Market research\n",
        "- News monitoring\n",
        "- Sentiment analysis\n",
        "- Email marketing\n",
        "- Collecting data for machine learning and deep learning models\n",
        "\n",
        "Web pages can either be scraped using APIs or parsing web pages.\n",
        "There are various libraries for parsing web pages using Python. These include BeautifulSoup, Scrapy, Selenium, ZenRows, Playwright etc."
      ],
      "metadata": {
        "id": "faTN-js5dQr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Legal and Ethical considerations for web scraping\n",
        "Just because data is present on the internet, it doesn't mean it can or should be scraped.\n",
        "Always look into permissions, what data can be scraped, how much can be scraped and how are you allowed to use this data.\n",
        "A robots.txt file specifies which pages of a website can and can't be accessed for crawling and scraping."
      ],
      "metadata": {
        "id": "7lxVjoJ7doZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular Expressions"
      ],
      "metadata": {
        "id": "k2JFCqDclM9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A regular expression (RegEx) is a sequence of characters that forms a search pattern. This is used to check if a string has a specified pattern.\n",
        "Regular expressions are used to select a specific pattern of information in web scraping.\n",
        "\n",
        "Function | Description\n",
        "---------|------------\n",
        "findall (match_pattern, search_string) | Returns a list containing all matches\n",
        "search (match_pattern, search_string) | Returns a Match object if there is a match anywhere in the string (only first occurrence)\n",
        "split (match_pattern, search_string, maxsplit) | Returns a list where the string has been split at each match\n",
        "sub (match_pattern, replacement, search_string, count) | Replaces one or many matches with a string\n"
      ],
      "metadata": {
        "id": "SFO0-Sl1lgeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "string = \"Stop the spinning top.\""
      ],
      "metadata": {
        "id": "4VfsSt8rlf-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = re.findall ('top', string)\n",
        "print(f)"
      ],
      "metadata": {
        "id": "jB9ogQvn7Sk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = re.split (' ', string)\n",
        "print(words)"
      ],
      "metadata": {
        "id": "czG5-wZ87VA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newstring = re.sub ('top', 'wheel', string)\n",
        "print(newstring)"
      ],
      "metadata": {
        "id": "9vLBm1nl7XVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Match Object**\n",
        "\n",
        "The Match object has information about the search and result.\n",
        "- .span() returns a tuple with the start and end position of the match.\n",
        "- .string returns the string passed to the search function.\n",
        "- .group() returns the part of the string where the match was found\n",
        "\n"
      ],
      "metadata": {
        "id": "7DszZSWG96gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"Stop the spinning top.\"\n",
        "\n",
        "x = re.search (r'spin', string)\n",
        "print(x)    # x = None if the pattern is not found\n",
        "print(\"span:\", x.span())\n",
        "print(\"string:\", x.string)\n",
        "print(\"group:\", x.group())"
      ],
      "metadata": {
        "id": "Ykk3_MKD9oRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Symbol | Description |\n",
        "|---|---|\n",
        "| ^ | Matches at the beginning of a line |\n",
        "| $ | Matches at the end of the line |\n",
        "| . | Matches any character |\n",
        "| \\s | Matches whitespace |\n",
        "| \\S | Matches any non-whitespace character |\n",
        "| * | Zero or more occurrences |\n",
        "| + | One or more occurrences |\n",
        "| ? | Zero or one occurrences |\n",
        "| [aeiou] | Matches a single character in the listed set |\n",
        "| [^XYZ] | Matches a single character not in the listed set |\n",
        "| [a-z0-9] | The set of characters can include a range |\n",
        "| ( | Indicates where string extraction is to start |\n",
        "| ) | Indicates where string extraction is to end |\n",
        "| \\b | Returns a match where the specified characters are at the beginning or at the end of a word |\n",
        "| \\B | Returns a match where the specified characters are present, but NOT at the beginning or at the end of a word |"
      ],
      "metadata": {
        "id": "GiSLGmAM0L7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt1 = 'the cat sits on the cot.'\n",
        "\n",
        "ex1 = re.findall('c.t', txt1)\n",
        "print(ex1)"
      ],
      "metadata": {
        "id": "aX5q_Ctn1JbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex2 = re.findall('the', txt1)\n",
        "print(ex2)"
      ],
      "metadata": {
        "id": "jR2S_j3x1K-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex3 = re.search('^the', txt1)\n",
        "if ex3:\n",
        "    print('present')\n",
        "else:\n",
        "    print('not present')"
      ],
      "metadata": {
        "id": "wNFF55DR1Nri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex4 = re.split('\\s', txt1)\n",
        "print(ex4)"
      ],
      "metadata": {
        "id": "5hkTc7up1PuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt2 = 'THE CAT EATS A CARROT IN THE CT SCAN.'\n",
        "\n",
        "ex5 = re.findall('C.?T', txt2)\n",
        "print('C.?T:', ex5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDeTN_oR4Vkp",
        "outputId": "732fb28d-e39b-4001-f932-806d2668562d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C.*T: ['CAT EATS A CARROT IN THE CT']\n",
            "C.+T: ['CAT EATS A CARROT IN THE CT']\n",
            "C.?T: ['CAT', 'CT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex6 = re.findall('C.*T', txt2)\n",
        "print('C.*T:', ex6)\n",
        "\n",
        "ex7 = re.findall('C.+T', txt2)\n",
        "print('C.+T:', ex7)"
      ],
      "metadata": {
        "id": "b6cfrEWA44kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex8 = re.findall(r'C.*?T', txt2)\n",
        "print(ex8)\n",
        "\n",
        "ex9 = re.findall(r'C.+?T', txt2)\n",
        "print(ex9)"
      ],
      "metadata": {
        "id": "SaLvTsaC5Bto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt3 = \"\"\"The majestic mountains towered above the quaint little village nestled in the valley, while the river meandered\n",
        "gently through the lush greenery, creating a serene and picturesque landscape.\"\"\"\n",
        "\n",
        "vowels = re.findall('[aeiouAEIOU]', txt3)\n",
        "print(len(vowels))\n",
        "consonants = re.findall('[^aeiouAEIOU0-9\\s\\W_]', txt3)\n",
        "print(len(consonants))"
      ],
      "metadata": {
        "id": "8Js1_5vf6U0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HTTP Libraries for Python\n",
        "In order to scrape data from websites, first a connection must be established with the website."
      ],
      "metadata": {
        "id": "ic1U4zBy7aFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**urllib** <br>\n",
        "urllib is a package that is part of the Python Standard Library. It has several modules for working with URLs like:\n",
        "- urllib.request for opening and reading URLs\n",
        "- urllib.error containing the exceptions raised by urllib.request\n",
        "- urllib.parse for parsing URLs\n",
        "- urllib.robotparser for parsing robots.txt files <br><br>\n",
        "It is suitable for simple tasks but lacks many features that are required for more complex web interactions."
      ],
      "metadata": {
        "id": "33le--vl7iuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**urllib3** <br>\n",
        "urllib3 is a powerful, user-friendly third-party HTTP client for Python, which includes additional features like:\n",
        "- Thread safety.\n",
        "- Connection pooling.\n",
        "- Client-side TLS/SSL verification.\n",
        "- File uploads with multipart encoding.\n",
        "- Helpers for retrying requests and dealing with HTTP redirects.\n",
        "- Support for gzip, deflate, brotli, and zstd encoding.\n",
        "- Proxy support for HTTP and SOCKS.\n",
        "- 100% test coverage."
      ],
      "metadata": {
        "id": "9smDGCzi8Lom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requests** <br>\n",
        "Requests is a simple and elegant HTTP library for Python, built on top of urllib3."
      ],
      "metadata": {
        "id": "0vasueIJ8cKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding HTTP Headers\n",
        "A HTTP header gives additional information (metadata) about the request or response. <br>\n",
        "There are 3 types of headers: General, Response and Request headers."
      ],
      "metadata": {
        "id": "_37EQzae8uiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping with API\n"
      ],
      "metadata": {
        "id": "9eaxaqUPb_cF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA66kp2sXap0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://openlibrary.org/search/authors.json?q=twain\"\n",
        "response = requests.get(url)\n",
        "\n",
        "print('Headers:')\n",
        "print(response.headers)"
      ],
      "metadata": {
        "id": "lEPhr9tcXoG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3442a4e-c889-4639-9675-89834d2106ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers:\n",
            "{'Server': 'nginx/1.18.0 (Ubuntu)', 'Date': 'Sat, 16 Mar 2024 06:51:25 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-allow-method': 'GET, OPTIONS', 'access-control-max-age': '86400', 'x-ol-stats': '\"SR 1 0.462 TT 0 0.480\"', 'Referrer-Policy': 'no-referrer-when-downgrade'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View response headers\n",
        "print(\"Response Headers:\")\n",
        "for header, value in response.headers.items():\n",
        "    print(f\"{header}: {value}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# View request headers\n",
        "print(\"Request Headers:\")\n",
        "for header, value in response.request.headers.items():\n",
        "    print(f\"{header}: {value}\")"
      ],
      "metadata": {
        "id": "Czs_ujtxYDlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View General Headers\n",
        "\n",
        "# Accessing Request URL\n",
        "request_url = response.url\n",
        "print(\"Request URL:\", request_url)\n",
        "\n",
        "# Accessing Request Method\n",
        "request_method = response.request.method\n",
        "print(\"Request Method:\", request_method)\n",
        "\n",
        "# Accessing Status Code\n",
        "status_code = response.status_code\n",
        "print(\"Status Code:\", status_code)\n",
        "\n",
        "# Accessing Referrer Policy\n",
        "referrer_policy = response.headers.get('Referrer-Policy')\n",
        "print(\"Referrer Policy:\", referrer_policy)"
      ],
      "metadata": {
        "id": "DIN5yQSiYhSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import robotparser\n",
        "rp_api = robotparser.RobotFileParser()\n",
        "rp_api.set_url(f\"{url}/robots.txt\")\n",
        "rp_api.read()\n",
        "print(rp_api.can_fetch('*', url))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igCH_d_3BcT2",
        "outputId": "47454b15-a7a9-4256-a7f6-80ab7555b54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info(book_name):\n",
        "    query_book = book_name.lower()\n",
        "    query_book = query_book.replace(' ', '+')\n",
        "\n",
        "    resp = requests.get(f\"http://openlibrary.org/search.json?title={query_book}\")\n",
        "    info = resp.json()\n",
        "\n",
        "    author_name = info['docs'][0]['author_name'][0]\n",
        "    publishing_year = info['docs'][0]['first_publish_year']\n",
        "    avg_rating = info['docs'][0]['ratings_average']\n",
        "    subjects = info['docs'][0]['subject']\n",
        "    people = info['docs'][0]['person']\n",
        "    print(f\"Author of '{book_name}' is {author_name}. It was first published in {publishing_year}. It has an average rating of {avg_rating}\")\n",
        "\n",
        "    return subjects, people"
      ],
      "metadata": {
        "id": "GZJFxgteZIdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book1 = input('Enter 1st book name: ')\n",
        "book2 = input('Enter 2nd book name: ')"
      ],
      "metadata": {
        "id": "z0BtMs2UZows"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub1, chars1 = get_info(book1)\n",
        "sub1 = set(sub1)\n",
        "chars1 = set(chars1)\n",
        "sub2, chars2 = get_info(book2)\n",
        "sub2 = set(sub2)\n",
        "chars2 = set(chars2)\n",
        "\n",
        "common_sub = list(sub1 & sub2)\n",
        "print('Common subjects are:',common_sub)\n",
        "common_chars = list(chars1 & chars2)\n",
        "print('Common characters are:',common_chars)"
      ],
      "metadata": {
        "id": "XCYnrp2HZy4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping with *BeautifulSoup*"
      ],
      "metadata": {
        "id": "7K2Z02bpcI9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request, urllib.parse\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WBpY2PsPcUpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_books(url):\n",
        "    # Lists to save Titles, Ratings aand Prices\n",
        "    Title = []\n",
        "    Rating = []\n",
        "    Price = []\n",
        "\n",
        "    html = urllib.request.urlopen(url).read()\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    books = soup.find('ol', class_='row').find_all('li', class_='col-xs-6 col-sm-4 col-md-3 col-lg-3')\n",
        "\n",
        "    for book in books:\n",
        "        title = book.find('h3').find('a').get('title')\n",
        "        print(\"Title:\", title)\n",
        "        Title.append(title)\n",
        "\n",
        "        star = book.find('p', class_='star-rating')\n",
        "        rating = star['class'][1]\n",
        "        print(\"Rating:\", rating)\n",
        "        Rating.append(rating)\n",
        "\n",
        "        price = book.find('p', class_=\"price_color\").text\n",
        "        print(\"Price:\", price)\n",
        "        Price.append(price)\n",
        "\n",
        "        print(\"----------\")\n",
        "\n",
        "    next_page_tag = soup.find('ul', class_ = 'pager').find('li', class_='next')\n",
        "    if next_page_tag:\n",
        "        next_url = next_page_tag.find('a')['href']\n",
        "        base_url = re.sub(r'(.*fiction_4/).*', r'\\1', url)\n",
        "        next_page_url = urllib.parse.urljoin(base_url, next_url)\n",
        "        next_page_data = scrape_books(next_page_url)\n",
        "        Title.extend(next_page_data[0])\n",
        "        Rating.extend(next_page_data[1])\n",
        "        Price.extend(next_page_data[2])\n",
        "\n",
        "    return Title, Rating, Price"
      ],
      "metadata": {
        "id": "3XCxf8-IAGuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_url = 'https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html'\n",
        "rp_webs = robotparser.RobotFileParser()\n",
        "rp_webs.set_url(f\"{start_url}/robots.txt\")\n",
        "rp_webs.read()\n",
        "print(rp_webs.can_fetch('*', start_url))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TILM9FDTAGsa",
        "outputId": "92c21f7b-3817-4200-d509-79555e0f3b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req = urllib.request.Request(start_url)\n",
        "response = urllib.request.urlopen(req)\n",
        "\n",
        "# View response headers\n",
        "print('\\nResponse Headers:')\n",
        "print(response.headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30cno53QH1v2",
        "outputId": "9074013d-d804-4275-f763-8604540bc972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response Headers:\n",
            "Date: Sat, 16 Mar 2024 07:24:27 GMT\n",
            "Content-Type: text/html\n",
            "Content-Length: 50109\n",
            "Connection: close\n",
            "Last-Modified: Wed, 08 Feb 2023 21:02:32 GMT\n",
            "ETag: \"63e40de8-c3bd\"\n",
            "Accept-Ranges: bytes\n",
            "Strict-Transport-Security: max-age=0; includeSubDomains; preload\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some General Headers\n",
        "print('final url:', response.geturl())\n",
        "print('status code:', response.getcode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfDjrhp5JlLo",
        "outputId": "2ca085a5-3d7b-4345-d869-5e6eda49efcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final url: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html\n",
            "status code: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles, ratings, prices = scrape_books(start_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ysTxFBWCVoT",
        "outputId": "7b8795a8-e4a4-4cf1-fd17-bf8f101a07cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Tipping the Velvet\n",
            "Rating: One\n",
            "Price: £53.74\n",
            "----------\n",
            "Title: Forever and Forever: The Courtship of Henry Longfellow and Fanny Appleton\n",
            "Rating: Three\n",
            "Price: £29.69\n",
            "----------\n",
            "Title: A Flight of Arrows (The Pathfinders #2)\n",
            "Rating: Five\n",
            "Price: £55.53\n",
            "----------\n",
            "Title: The House by the Lake\n",
            "Rating: One\n",
            "Price: £36.95\n",
            "----------\n",
            "Title: Mrs. Houdini\n",
            "Rating: Five\n",
            "Price: £30.25\n",
            "----------\n",
            "Title: The Marriage of Opposites\n",
            "Rating: Four\n",
            "Price: £28.08\n",
            "----------\n",
            "Title: Glory over Everything: Beyond The Kitchen House\n",
            "Rating: Three\n",
            "Price: £45.84\n",
            "----------\n",
            "Title: Love, Lies and Spies\n",
            "Rating: Two\n",
            "Price: £20.55\n",
            "----------\n",
            "Title: A Paris Apartment\n",
            "Rating: Four\n",
            "Price: £39.01\n",
            "----------\n",
            "Title: Lilac Girls\n",
            "Rating: Two\n",
            "Price: £17.28\n",
            "----------\n",
            "Title: The Constant Princess (The Tudor Court #1)\n",
            "Rating: Three\n",
            "Price: £16.62\n",
            "----------\n",
            "Title: The Invention of Wings\n",
            "Rating: One\n",
            "Price: £37.34\n",
            "----------\n",
            "Title: World Without End (The Pillars of the Earth #2)\n",
            "Rating: Four\n",
            "Price: £32.97\n",
            "----------\n",
            "Title: The Passion of Dolssa\n",
            "Rating: Five\n",
            "Price: £28.32\n",
            "----------\n",
            "Title: Girl With a Pearl Earring\n",
            "Rating: One\n",
            "Price: £26.77\n",
            "----------\n",
            "Title: Voyager (Outlander #3)\n",
            "Rating: Five\n",
            "Price: £21.07\n",
            "----------\n",
            "Title: The Red Tent\n",
            "Rating: Five\n",
            "Price: £35.66\n",
            "----------\n",
            "Title: The Last Painting of Sara de Vos\n",
            "Rating: Two\n",
            "Price: £55.55\n",
            "----------\n",
            "Title: The Guernsey Literary and Potato Peel Pie Society\n",
            "Rating: One\n",
            "Price: £49.53\n",
            "----------\n",
            "Title: Girl in the Blue Coat\n",
            "Rating: Two\n",
            "Price: £46.83\n",
            "----------\n",
            "Title: Between Shades of Gray\n",
            "Rating: Five\n",
            "Price: £20.79\n",
            "----------\n",
            "Title: While You Were Mine\n",
            "Rating: Five\n",
            "Price: £41.32\n",
            "----------\n",
            "Title: The Secret Healer\n",
            "Rating: Three\n",
            "Price: £34.56\n",
            "----------\n",
            "Title: Starlark\n",
            "Rating: Three\n",
            "Price: £25.83\n",
            "----------\n",
            "Title: Lost Among the Living\n",
            "Rating: Four\n",
            "Price: £27.70\n",
            "----------\n",
            "Title: A Spy's Devotion (The Regency Spies of London #1)\n",
            "Rating: Five\n",
            "Price: £16.97\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Title': titles, 'Rating': ratings, 'Price': prices}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "yiBV8VBsANZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Price'] = df['Price'].str.replace('£', '')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7935q9-AbUu",
        "outputId": "12176b06-367e-4b97-967f-70d24d7243ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Title Rating  Price\n",
            "0                                  Tipping the Velvet    One  53.74\n",
            "1   Forever and Forever: The Courtship of Henry Lo...  Three  29.69\n",
            "2             A Flight of Arrows (The Pathfinders #2)   Five  55.53\n",
            "3                               The House by the Lake    One  36.95\n",
            "4                                        Mrs. Houdini   Five  30.25\n",
            "5                           The Marriage of Opposites   Four  28.08\n",
            "6     Glory over Everything: Beyond The Kitchen House  Three  45.84\n",
            "7                                Love, Lies and Spies    Two  20.55\n",
            "8                                   A Paris Apartment   Four  39.01\n",
            "9                                         Lilac Girls    Two  17.28\n",
            "10         The Constant Princess (The Tudor Court #1)  Three  16.62\n",
            "11                             The Invention of Wings    One  37.34\n",
            "12    World Without End (The Pillars of the Earth #2)   Four  32.97\n",
            "13                              The Passion of Dolssa   Five  28.32\n",
            "14                          Girl With a Pearl Earring    One  26.77\n",
            "15                             Voyager (Outlander #3)   Five  21.07\n",
            "16                                       The Red Tent   Five  35.66\n",
            "17                   The Last Painting of Sara de Vos    Two  55.55\n",
            "18  The Guernsey Literary and Potato Peel Pie Society    One  49.53\n",
            "19                              Girl in the Blue Coat    Two  46.83\n",
            "20                             Between Shades of Gray   Five  20.79\n",
            "21                                While You Were Mine   Five  41.32\n",
            "22                                  The Secret Healer  Three  34.56\n",
            "23                                           Starlark  Three  25.83\n",
            "24                              Lost Among the Living   Four  27.70\n",
            "25  A Spy's Devotion (The Regency Spies of London #1)   Five  16.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('books_data.csv', index=False)"
      ],
      "metadata": {
        "id": "9FjxxLWGAjFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}